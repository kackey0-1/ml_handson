{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 予測精度の評価と変数選択"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* **当てはめ精度**: 手持ちのデータに対してモデルを適用した時の当てはまり度合い\n",
    "* **予測精度**: まだ手に入れていないデータに対してモデルを適用した時の、当てはまり度合い\n",
    "\n",
    "* **過学習**: 当てはめの精度は高いのに、予測精度が低くなること\n",
    "  * 手持ちデータに過剰に適合しすぎたモデルを構築してしまうことが原因で発生する\n",
    "\n",
    "* **汎用誤差**: まだ他に入れていないデータに対する予測誤差のこと\n",
    "* **訓練データ・テストデータ**\n",
    "  * 訓練データ: パラメタの検定に用いられたデータのこと\n",
    "  * テストデータ: 汎用誤差を評価するために、パラメタ推定時にあえて使わずに残しておいたデータのこと\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 変数選択の意義\n",
    "\n",
    "* 過学習を引き起こしてしまうありがちな原因は、説明変数を増やしすぎてしまうこと\n",
    "* モデルの作成において、不要な説明変数を除くことで予測精度が上がる可能性がある\n",
    "  * 不要な説明変数(=応答変数に影響を及ぼさない説明変数)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## クロスバリデーション(交差検証法)\n",
    "\n",
    "Cross Validation(CV)は、データを一定の規則に基づいて訓練データとテストデータに分け、テストデータに対する予測精度を評価する方法\n",
    "\n",
    "  * **leave-p-out CV**: 手持ちデータからp個のデータを取り除き、テストデータに使う方法\n",
    "  * **K-fold CV**: 手持ちのデータをK個のグループに分割する。そのグループの1つを取り除いてテストデータとする。これをK回繰り返して、予測精度の平均値を評価値として用いる"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 赤池の情報量基準(=AIC)\n",
    "\n",
    "$$ AIC = 2 \\times (最大化対数尤度 - 推定されたパラメタの個数) $$\n",
    "\n",
    "**AICが小さければ小さいほどよいモデル**であると見なされる\n",
    "\n",
    "対数尤度が大きければ大きいほど、当てはめ精度は高いとみなせる。しかし、当てはめ精度をあげることに注力すると、汎化誤差が大きくなってしまう。そこでAICでは、推定されたパラメタの個数を罰則として用いる。\n",
    "\n",
    "説明変数を増やすと対数尤度が大きくなるが、同時に罰則も大きくなる。\n",
    "AICは**罰則が増えることを補って余るほどに対数尤度が増えるかどうかを判定している指標**だとみなすことができる。それにより、AICを使うことで不要な変数を除くことが可能になる。\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 相対エントロピー\n",
    "\n",
    "AICは統計モデルの予測の良さを重要視する。統計モデルにおける予測は確率分布であることから真の分布と統計モデルにより得られた分布との差は重要な要素になるといえる。\n",
    "\n",
    "確率分布の差異を測る指標を、**相対エントロピー**と呼ぶ\n",
    "\n",
    "相対エントロピーは分布間の擬距離とも呼ばれ、以下のように計算される。(g(x), f(x)は確率密度関数)\n",
    "\n",
    "$$\n",
    "相対エントロピー = \\int{g(x)\\log{\\frac{g(x)}{f(x)}}}dx\n",
    "$$\n",
    "そして、以下のように変形可能\n",
    "$$\n",
    "相対エントロピー = \\int{g(x)\\log{g(x)}-\\log{{f(x)}}}}dx\n",
    "$$\n",
    "\n",
    "確率密度関数から期待値を計算する式の再揚\n",
    "\n",
    "$$\n",
    "xの期待値 = \\int{f(x)xdx}\n",
    "$$\n",
    "\n",
    "相対エントロピーは、2つの確率密度関数の対数の差`log g(x) - log f(x)`の期待値であるとみなすことができる"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 相対エントロピーの最小化と平均対数尤度\n",
    "\n",
    "真の分布と予測された分布との距離を小さくすることを考える(yは応答変数であり、g(x)が真の分布であり、f(x)がモデルから予測された分布)\n",
    "\n",
    "$$\n",
    "\\int{g(y)^{\\log{g(y)}-\\log{f(y)}}}dy\n",
    "$$\n",
    "\n",
    "以下のように変形\n",
    "\n",
    "$$\n",
    "[\\int{g(y)\\log{g(y)}-g(y)\\log{f(y)}}]dy\n",
    "$$\n",
    "ここで、真の分布g(y)は変更できない(真の分布であるため)ため、この距離を小さくするためには、以下の部分を最小にすると良いことになる\n",
    "\n",
    "$$\n",
    "\\int{-g(y)\\log{f(y)}dy}\n",
    "$$\n",
    "\n",
    "上記の式からマイナスをとったものを、**平均対数尤度**と呼ぶ\n",
    "平均対数尤度は真の分布から乱数生成シミュレーションを何度も行い、シミュレーションで得られたデータとモデルから予測された分布から対数尤度を何度も計算し、その平均値をとったものと解釈できる。つまり、真の分布と推定された分布の差異を最小にすることは、平均対数尤度にマイナスをかけたものを最小にすることを意味する。\n",
    "\n",
    "平均対数尤度を最大にすることで、真の分布と予測された分布の差異を最小にできる"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* 平均対数尤度をそのものを計算することは難しいため、最大化対数尤度で代用する\n",
    "* しかし、最大化対数尤度は平均対数尤度よりも大きすぎるバイアスがかかる\n",
    "  * このバイアスの大きさは、推定されたパラメタの個数であることが数学的に証明済み\n",
    "* そのため、このバイアスを取り除いたものがAICとなり、以下のように計算\n",
    "\n",
    "$$ AIC = 2 \\times (最大対数尤度-推定されたパラメタの個数) $$\n",
    "\n",
    "推定されたパラメタの個数で最大対数尤度を引くことには、上記のような理由があるわけ"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 検定の"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 検定とAICのどちらを使うべきか\n",
    "\n",
    "* **検定**: 検定を用いて、平均値に有意なさがあるかどうかを判断する手法\n",
    "* **AIC**: 真の分布から乱数生成シミュレーションを何度も行い、シミュレーションから得られたデータとモデルから予測された分布から対数尤度を何度も計算し、その平均値をとったものと解釈できる。つまり、未知のデータへの予測精度をあげる目的で考案された指標指標。\n",
    "\n",
    "検定とAICでどちらの方が優れているということは判別できない\n",
    "ここで重要なのは、両方ともの解釈ができるようになることが重要"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
